{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e3d1aa9-537b-4b6e-9c06-51b8ed8bdeab",
   "metadata": {},
   "source": [
    "# Isochronous sequences with target speech stimulus\n",
    "\n",
    "For this example, we will attempt to recreate the stimuli from the first experiment in [Bosker (2017)](https://link.springer.com/article/10.3758/s13414-016-1206-4#Sec1). "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6e572ea-10c1-40ce-8213-0425a300bb6f",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "Before we start, we import the necessary classes from *thebeat*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec6730-a7c6-424a-8b27-b93f871a109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thebeat.core import Sequence, SoundStimulus, SoundSequence\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c22f50-09b8-46cf-a5ad-4472e6cb9d88",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We suppress warnings, but let's hide that to avoid confusion\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aa266d-d336-4a64-a90b-e3d308a4d87d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "In the first experiment in that paper, the author tested whether the tempo of a sequence of pure tones changes the perception of a subsequently presented speech sound that was somewhere in between /ɑs/ and /aːs/. The relevant bits from the method section are replicated here:\n",
    "\n",
    "> \"The stimuli in the experiment consisted of tone precursors followed by target words (see Fig. 1). Four different precursors, each with a total duration of 4 seconds, were created in Praat (Boersma & Weenink, 2012) by crossing two different tone durations (71 vs. 125 ms) with two presentation rates (4 vs. 7 Hz). The fundamental frequency of all pure tones was fixed at 440 Hz, thus avoiding spectral masking of the target vowels’ F0, F1, and F2. \""
   ]
  },
  {
   "cell_type": "raw",
   "id": "af6b8e8e-d083-4a91-9ca8-07f3d1cbe48d",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    ".. figure:: bosker.png\n",
    "    :align: center\n",
    "    \n",
    "    \"Examples of the precursor conditions used in the different experiments. The top panel (Conditions A, B, C, and D) shows the isochronous precursor conditions used in Experiments 1–3. Each plot shows the final second of a tone sequence (total duration = 4 s), followed by a target word, with the precursor condition given to the left\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfe58b4-dd08-4852-ab70-225d243f0979",
   "metadata": {
    "tags": []
   },
   "source": [
    "Replicated from [Bosker (2017)](https://link.springer.com/article/10.3758/s13414-016-1206-4#Sec1) with permission from the author.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7bf21d75-e2b7-4b9a-b214-7fbd2255938c",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "We will do the following:\n",
    "\n",
    "* We make two :py:class:`~thebeat.core.Sequence` objects:\n",
    "\n",
    "  * slow (17 events, ioi=1000/4=250 ms)\n",
    "  * fast (29 events, ioi=1000/7~=143 ms)\n",
    "\n",
    "* We make two :py:class:`~thebeat.core.SoundStimulus` objects:\n",
    "\n",
    "  * short = 71 ms at 440 Hz\n",
    "  * long = 125 ms at 440 Hz\n",
    "\n",
    "Then we make the four combinations into trials, adding in the target stimulus at the end.\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d4e581-8f0b-4a24-886d-8804e33a62c8",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "## Making the sequences"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05df6681-dd4f-48ec-ace1-2a669cb855c6",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "For this we will use the :py:class:`~thebeat.core.Sequence` class and its :py:meth:`~thebeat.core.Sequence.generate_isochronous` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efae13-8ff5-4041-96a8-fada4a18fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_slow = Sequence.generate_isochronous(n_events=17, ioi=250)\n",
    "seq_fast = Sequence.generate_isochronous(n_events=29, ioi=1000/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aba66b-48f0-4ab0-bc7a-ee1a09ef12b9",
   "metadata": {},
   "source": [
    "If we want to see what the sequences look like, we can plot the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b71b90-1866-4d90-a3e1-71198aa6c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_slow.plot_sequence(x_axis_label=\"Time (ms)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de12104-642f-454b-8f6f-9b82fb6717dc",
   "metadata": {},
   "source": [
    "## Making the stimuli\n",
    "All sounds in the experiment had a 20 ms raised-cosine on- and off-ramp. The durations were respectively 71 and 125 ms for the short and long sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100eab9-782c-4df4-aa85-c91bec2a562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_short = SoundStimulus.generate(freq=440, duration_ms=71, \n",
    "                                    onramp_ms=20, offramp_ms=20,\n",
    "                                    ramp_type='raised-cosine')\n",
    "stim_long = SoundStimulus.generate(freq=440, duration_ms=125, \n",
    "                                   onramp_ms=20, offramp_ms=20,\n",
    "                                   ramp_type='raised-cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788e13b9-aea6-46a9-8136-bba02cb498b2",
   "metadata": {},
   "source": [
    "See what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a85136-7817-4aa4-a11a-0dfe6950b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_short.plot_waveform();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f9efd-d5af-462c-ad47-6453768ebd18",
   "metadata": {},
   "source": [
    "## Making the trials\n",
    "We will make 4 types of trials. For the slow sequences, we need 16 tones plus one target stimulus. For the long sequences, we need 28 tones plus one target stimulus. You can download the target stimulus as a ``.wav`` file [here](aas.wav), but you can easily use another audio files instead: ``SoundStimulus.from_wav('yourfile.wav')``.\n",
    "\n",
    "Make sure to save the ``.wav`` file to a location that you can access easily in your Python script. For instance in the same folder as the script itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac29ade-3c8a-4713-9ac1-65d74b0767f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = SoundStimulus.from_wav('aas.wav')\n",
    "\n",
    "# Adjust the amplitude of the target slightly\n",
    "target.change_amplitude(1.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a398eca-d828-4369-9087-793bb41e9449",
   "metadata": {},
   "source": [
    "We first make lists for the stimuli. 16 or 28 times the created stimulus followed by one time the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0796bf75-f6ea-4922-a379-1f5e7b8d82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stims_slowlong = [stim_long] * 16 + [target]\n",
    "stims_slowshort = [stim_short] * 16 + [target]\n",
    "stims_fastlong = [stim_long] * 28 + [target]\n",
    "stims_fastshort = [stim_short] * 28 + [target]\n",
    "\n",
    "# Print one to see what the lists look like\n",
    "print(stims_slowlong)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f239fcc2-3b36-455a-9b77-09acae76fd47",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "We are ready to make the trials. We'll use :py:class:`~thebeat.core.SoundSequence` for that. Optionally, you can give the trial a name, but you don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6960b-b4b7-44c9-8615-635fba68a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_slowlong = SoundSequence(stims_slowlong, seq_slow, name=\"Slow trial with long sounds\")\n",
    "trial_slowshort = SoundSequence(stims_slowshort, seq_slow)\n",
    "trial_fastlong = SoundSequence(stims_fastlong, seq_fast)\n",
    "trial_fastshort = SoundSequence(stims_fastshort, seq_fast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdf8e8-b0b0-458a-a553-44695f5ee253",
   "metadata": {},
   "source": [
    "That's it! We can plot these trials (``.plot_waveform()`` or ``.plot_sequence()``), we can play them (``.play()``) or we can write them to disk (``.write_wav()``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ee2ca1-ebad-4746-9ae4-ca7cd4de2e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_slowlong.plot_waveform();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c9dcb7-d32f-4331-ac18-cb064abea0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can listen to the sound here. You can ignore this code, it's only for this website.\n",
    "# In your Python editor you would simply use e.g. trial_slowlong.play()\n",
    "from IPython.display import Audio\n",
    "Audio(data=trial_slowlong.samples, rate=trial_slowlong.fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a526b8-24b4-4263-a3e3-ccb41ff8a29c",
   "metadata": {},
   "source": [
    "## Code summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b5cbe2-7bee-4a60-be4a-17c2d9459fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thebeat.core import Sequence, SoundStimulus, SoundSequence\n",
    "import numpy as np\n",
    "import importlib.resources as pkg_resources\n",
    "import thebeat.resources\n",
    "\n",
    "rng = np.random.default_rng(seed=123)\n",
    "\n",
    "seq_slow = Sequence.generate_isochronous(n_events=17, ioi=250)\n",
    "seq_fast = Sequence.generate_isochronous(n_events=29, ioi=1000/7)\n",
    "\n",
    "stim_short = SoundStimulus.generate(freq=440, duration_ms=71, onramp_ms=10, offramp_ms=10)\n",
    "stim_long = SoundStimulus.generate(freq=440, duration_ms=125, onramp_ms=10, offramp_ms=10)\n",
    "\n",
    "target = SoundStimulus.from_wav('aas.wav')\n",
    "target.change_amplitude(1.7)\n",
    "\n",
    "stims_slowlong = [stim_long] * 16 + [target]\n",
    "stims_slowshort = [stim_short] * 16 + [target]\n",
    "stims_fastlong = [stim_long] * 28 + [target]\n",
    "stims_fastshort = [stim_short] * 28 + [target]\n",
    "\n",
    "trial_slowlong = SoundSequence(stims_slowlong, seq_slow)\n",
    "trial_slowshort = SoundSequence(stims_slowshort, seq_slow)\n",
    "trial_fastlong = SoundSequence(stims_fastlong, seq_fast)\n",
    "trial_fastshort = SoundSequence(stims_fastshort, seq_fast)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
