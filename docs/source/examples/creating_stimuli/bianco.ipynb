{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b76b0eb-c592-4868-bb9a-08ad22895b2b",
   "metadata": {},
   "source": [
    "# Rapid tone-pip sequences\n",
    "\n",
    "Here we attempt to recreate the auditory stimuli used in [Bianco et al. (2020)](https://doi.org/10.7554/eLife.56073).\n",
    "\n",
    "Read the abstract, and check out [Figure 1](https://elifesciences.org/articles/56073#fig1).\n",
    "\n",
    "We will recreate the RAN and RANREG sequences here. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41f974d0-b1bc-469a-beb7-c5ca077c8e43",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "First we import some things, and we will create a :class:`numpy.random.Generator` object with a `random seed <https://en.wikipedia.org/wiki/Random_seed>`_ so you will get the same output as we."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b46e0-0bdb-43bb-9d31-8ae15bd62e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thebeat.core import Sequence, SoundStimulus, SoundSequence\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d30a5-ac0d-4b52-a2f5-eef5cbe313d3",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We suppress warnings, but let's hide that to avoid confusion\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1f06286-42e4-452b-93bc-63cc910c78a9",
   "metadata": {},
   "source": [
    "## Creating the RAN sequence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2780c34-ecfd-4790-80a1-2b6e8671311b",
   "metadata": {},
   "source": [
    "These sequences were random sequences with a number of properties:\n",
    "\n",
    "* The **sequences** were isochronous, had 140 events (i.e. total duration was 7 seconds), and had an inter-onset interval (IOI) of 50 ms.\n",
    "* The **sounds** had a duration equal to the IOI of 50 ms, so there was no silence in between the sounds.\n",
    "* The sounds themselves were tone-pips of different frequencies. The frequencies were randomly sampled from twenty values logarithmically spaced between 222 Hz and 2000 Hz.\n",
    "* An additional constraint was that no two the same frequencies could occur consecutively, which is why we use the ``while`` loop that keeps on sampling if the newly chosen frequency was the same as the last one in the list of already-sampled frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f733b-c220-4ae4-a901-5699b156863f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample the sounds' frequencies with the constraint that no \n",
    "# two the same frequencies can occur consecutively.\n",
    "\n",
    "freqs = np.geomspace(222, 2000, 20)\n",
    "\n",
    "freqs_sample = [rng.choice(freqs)]\n",
    "\n",
    "for _ in range(139):  # sample the other 139 tone freqs\n",
    "    choice = rng.choice(freqs)\n",
    "    while choice == freqs_sample[-1]: \n",
    "        choice = rng.choice(freqs)\n",
    "    freqs_sample.append(choice) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010eeb8b-ca20-4627-af03-f6a0d94a3c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the sequence\n",
    "seq = Sequence.generate_isochronous(n_events=140, ioi=50)\n",
    "\n",
    "# Create the sounds\n",
    "stims = [SoundStimulus.generate(freq=freq, \n",
    "                           duration_ms=50, \n",
    "                           onramp_ms=5, \n",
    "                           offramp_ms=5, \n",
    "                           ramp_type='raised-cosine') for freq in freqs_sample]\n",
    "\n",
    "# Make the trial\n",
    "RAN_trial = SoundSequence(stims, seq, name=\"RAN sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb0fd6-d17a-4a3d-b5f8-03b870e50656",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAN_trial.plot_sequence(linewidth=10, figsize=(10, 2));\n",
    "# RAN_trial.write_wav('example_RAN.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc934c59-dfc0-431e-8fcf-dc227da86d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only so you can listen to the sound here. On your computer, simply execute RAN_trial.play()\n",
    "from IPython.display import Audio\n",
    "Audio(RAN_trial.samples, rate=RAN_trial.fs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "664fe1d0-d8fd-4914-9fe2-7062db3f7356",
   "metadata": {},
   "source": [
    "## Creating the RAN_REG sequence\n",
    "From a random point in the sequence, we start cycling a shorter sequence.\n",
    "\n",
    "* At a random point between 3000 and 4000 ms the sequences suddenly becomes regular\n",
    "* A cycle of 20 frequencies is then repeated until the end of the sequence\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d26b6dd-49d4-44fb-a1d5-ccad1e3fb3e9",
   "metadata": {},
   "source": [
    "### Creating the regular cycle frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b134046-a71c-4eb0-a4df-8a89fd1af7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freqs for the regular cycle\n",
    "freqs = np.geomspace(222, 2000, 20)\n",
    "cycle_freqs = [rng.choice(freqs)]\n",
    "\n",
    "for _ in range(19):\n",
    "    choice = rng.choice(freqs)\n",
    "    while choice == freqs_sample[-1]:\n",
    "        choice = rng.choice(freqs)\n",
    "    cycle_freqs.append(choice)\n",
    "\n",
    "change_event_index = int(rng.choice(np.arange(3000/50, 4000/50)))\n",
    "random_bit = freqs_sample[:change_event_index]\n",
    "ran_reg = random_bit + cycle_freqs * 4  # combine random bit and 4 cycles (which will be enough)\n",
    "ran_reg = ran_reg[:140] # Trim to 140 events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e96698c-b344-45df-b986-833a33a4a88b",
   "metadata": {},
   "source": [
    "### Combing the random part with the regular cycle\n",
    "\n",
    "It will be easiest to start doing that from a certain event, rather than millisecond, so let's assume we can choose an index where it starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c0f383-c135-4f74-994a-e7d7f5500be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_event_index = int(rng.choice(np.arange(3000/50, 4000/50)))\n",
    "random_bit = freqs_sample[:change_event_index]\n",
    "ran_reg = random_bit + cycle_freqs * 4  # combine random bit and 4 cycles (which will be enough)\n",
    "ran_reg = ran_reg[:140] # Trim to 140 events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e76385a7-b193-4962-9293-0086c4fae965",
   "metadata": {},
   "source": [
    "### Combine them into a SoundSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866b93f-7a02-4f7b-9e4f-5cd8799abf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sequence\n",
    "seq = Sequence.generate_isochronous(n_events=140, ioi=50)\n",
    "\n",
    "# Create the sounds\n",
    "stims = [SoundStimulus.generate(freq=freq, \n",
    "                                duration_ms=50, \n",
    "                                onramp_ms=5, \n",
    "                                offramp_ms=5, \n",
    "                                ramp_type='raised-cosine') for freq in ran_reg]\n",
    "\n",
    "# Make the trial\n",
    "RANREG_trial = SoundSequence(stims, seq, name=\"RANREG sequence\")\n",
    "\n",
    "# Plot it\n",
    "RANREG_trial.plot_sequence(linewidth=10, figsize=(10, 2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb68dc-f8dd-4a1b-a31d-6441481aa356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only so you can listen to the sound here. On your computer, simply execute RAN_trial.play()\n",
    "from IPython.display import Audio\n",
    "Audio(RANREG_trial.samples, rate=RANREG_trial.fs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f2a94ba-87c7-4e6e-a6f4-369d221077e4",
   "metadata": {},
   "source": [
    "## Bonus: Plotting spectrograms using Parselmouth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b843ec94-c4cd-44a4-86b7-fdc45344c8d7",
   "metadata": {},
   "source": [
    "### RAN sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eff272d-848f-4a09-9d46-e4bba2049cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For making spectrogram\n",
    "def draw_spectrogram(spectrogram, dynamic_range=5):\n",
    "    X, Y = spectrogram.x_grid(), spectrogram.y_grid()\n",
    "    sg_db = 10 * np.log10(spectrogram.values)\n",
    "    fig, ax = plt.subplots(figsize=(14, 4), tight_layout=True)\n",
    "    ax.pcolormesh(X, Y, sg_db, vmin=sg_db.max() - dynamic_range, cmap='afmhot')\n",
    "    ax.axes.set_ylim([spectrogram.ymin, 2150])\n",
    "    ax.axes.set_xlabel(\"Time [s]\")\n",
    "    ax.axes.set_ylabel(\"Frequency [Hz]\")\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "    \n",
    "parselmouth_sound = parselmouth.Sound(values=RAN_trial.samples, sampling_frequency=RAN_trial.fs)\n",
    "spectrogram = parselmouth_sound.to_spectrogram()\n",
    "\n",
    "fig, ax = draw_spectrogram(spectrogram)\n",
    "fig.savefig('spectrogram.png', dpi=600)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c9631dd-0428-4c70-b573-1caae56683a6",
   "metadata": {},
   "source": [
    "### RANREG sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f427cde9-9af6-43b5-b2b3-05569484ff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parselmouth_sound = parselmouth.Sound(values=RANREG_trial.samples, sampling_frequency=RANREG_trial.fs)\n",
    "spectrogram = parselmouth_sound.to_spectrogram()\n",
    "\n",
    "fig, ax = draw_spectrogram(spectrogram)\n",
    "fig.savefig('ranreg.png', dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
