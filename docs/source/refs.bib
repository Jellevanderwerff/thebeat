@article{burchardtNovelIdeasFurther2021,
  title = {Novel Ideas to Further Expand the Applicability of Rhythm Analysis},
  author = {Burchardt, Lara S. and Briefer, Elodie F. and Kn{\"o}rnschild, Mirjam},
  year = {2021},
  journal = {Ecology and Evolution},
  volume = {11},
  number = {24},
  pages = {18229--18237},
  doi = {10.1002/ece3.8417},
  abstract = {The temporal structure of animals' acoustic signals can inform about context, urgency, species, individual identity, or geographical origin. We present three independent ideas to further expand the applicability of rhythm analysis for isochronous, that is, metronome-like, rhythms. A description of a rhythm or beat needs to include a description of its goodness of fit, meaning how well the rhythm describes a sequence. Existing goodness-of-fit values are not comparable between methods and datasets. Furthermore, they are strongly correlated with certain parameters of the described sequence, for example, the number of elements in the sequence. We introduce a new universal goodness-of-fit value, ugof, comparable across methods and datasets, which illustrates how well a certain beat frequency in Hz describes the temporal structure of a sequence of elements. We then describe two additional approaches to adapt already existing methods to analyze the rhythm of acoustic sequences of animals. The new additions, a slightly modified way to use the already established Fourier analysis and concrete examples on how to use the visualization with recurrence plots, enable the analysis of more variable data, while giving more details than previously proposed measures. New methods are tested on 6 datasets including the very complex flight songs of male skylarks. The ugof is the first goodness-of-fit value capable of giving the information per element, instead of only per sequence. Advantages and possible interpretations of the new approaches are discussed. The new methods enable the analysis of more variable and complex communication signals. They give indications on which levels and structures to analyze and enable to track changes and differences in individuals or populations, for instance, during ontogeny or across regions. Especially, the ugof is not restricted to the analysis of acoustic signals but could for example also be applied on heartbeat measurements. Taken together, the ugof and proposed method additions greatly broaden the scope of rhythm analysis methods.},
  langid = {english}
}

@article{jacobyIntegerRatioPriors2017,
  title = {Integer Ratio Priors on Musical Rhythm Revealed Cross-Culturally by Iterated Reproduction},
  author = {Jacoby, Nori and McDermott, Josh H.},
  year = {2017},
  journal = {Current Biology},
  volume = {27},
  number = {3},
  pages = {359--370},
  doi = {10.1016/j.cub.2016.12.031},
  abstract = {Probability distributions over external states (priors) are essential to the interpretation of sensory signals. Priors for cultural artifacts such as music and language remain largely uncharacterized, but likely constrain cultural transmission, because only those signals with high probability under the prior can be reliably reproduced and communicated. We developed a method to estimate priors for simple rhythms via iterated reproduction of random temporal sequences. Listeners were asked to reproduce random ``seed'' rhythms; their reproductions were fed back as the stimulus and over time became dominated by internal biases, such that the prior could be estimated by applying the procedure multiple times. We validated that the measured prior was consistent across the modality of reproduction and that it correctly predicted perceptual discrimination. We then measured listeners' priors over the entire space of two- and three-interval rhythms. Priors in US participants showed peaks at rhythms with simple integer ratios and were similar for musicians and non-musicians. An analogous procedure produced qualitatively different results for spoken phrases, indicating some specificity to music. Priors measured in members of a native Amazonian society were distinct from those in US participants but also featured integer ratio peaks. The results do not preclude biological constraints favoring integer ratios, but they suggest that priors on musical rhythm are substantially modulated by experience and may simply reflect the empirical distribution of rhythm that listeners encounter. The proposed method can efficiently map out a high-resolution view of biases that shape transmission and stability of simple reproducible patterns within a culture.},
  langid = {english}
}

@article{jadoulSeekingTemporalPredictability2016,
  title = {Seeking Temporal Predictability in Speech: Comparing Statistical Approaches on 18 World Languages},
  shorttitle = {Seeking Temporal Predictability in Speech},
  author = {Jadoul, Yannick and Ravignani, Andrea and Thompson, Bill and Filippi, Piera and {de Boer}, Bart},
  year = {2016},
  journal = {Frontiers in Human Neuroscience},
  volume = {10},
  publisher = {Frontiers},
  doi = {10.3389/fnhum.2016.00586},
  abstract = {Temporal regularities in speech, such as interdependencies in the timing of speech events, are thought to scaffold early acquisition of the building blocks in speech. By providing on-line clues to the location and duration of upcoming syllables, temporal structure may aid segmentation and clustering of continuous speech into separable units. This hypothesis tacitly assumes that learners exploit predictability in the temporal structure of speech. Existing measures of speech timing tend to focus on first-order regularities among adjacent units, and are overly sensitive to idiosyncrasies in the data they describe. Here, we compare several statistical methods on a sample of 18 languages, testing whether syllable occurrence is predictable over time. Rather than looking for differences between languages, we aim to find across languages (using clearly defined acoustic, rather than orthographic, measures), temporal predictability in the speech signal which could be exploited by a language learner. First, we analyse distributional regularities using two novel techniques: a Bayesian ideal learner analysis, and a simple distributional measure. Second, we model higher-order temporal structure \textendash{} regularities arising in an ordered series of syllable timings \textendash{} testing the hypothesis that non-adjacent temporal structures may explain the gap between subjectively-perceived temporal regularities, and the absence of universally-accepted lower-order objective measures. Together, our analyses provide limited evidence for predictability at different time scales, though higher-order predictability is difficult to reliably infer. We conclude that temporal predictability in speech may well arise from a combination of individually weak perceptual cues at multiple structural levels, but is challenging to pinpoint.},
  langid = {english}
}

@article{postEditDistanceMeasure2011,
  title = {The Edit Distance as a Measure of Perceived Rhythmic Similarity},
  author = {Post, Olaf and Toussaint, Godfried},
  year = {2011},
  journal = {Empirical Musicology Review},
  volume = {6},
  number = {3},
  pages = {164--179},
  publisher = {Empirical Musicology Review},
  doi = {10.18061/1811/52811},
  abstract = {The `edit distance' (or `Levenshtein distance') measure of distance between two data sets is defined as the minimum number of editing operations \textendash{} insertions, deletions, and substitutions \textendash{} that are required to transform one data set to the other (Orpen and Huron, 1992). This measure of distance has been applied frequently and successfully in music information retrieval, but rarely in predicting human perception of distance. In this study, we investigate the effectiveness of the edit distance as a predictor of perceived rhythmic dissimilarity under simple rhythmic alterations. Approaching rhythms as a set of pulses that are either onsets or silences, we study two types of alterations. The first experiment is designed to test the model's accuracy for rhythms that are relatively similar; whether rhythmic variations with the same edit distance to a source rhythm are also perceived as relatively similar by human subjects. In addition, we observe whether the salience of an edit operation is affected by its metric placement in the rhythm. Instead of using a rhythm that regularly subdivides a 4/4 meter, our source rhythm is a syncopated 16-pulse rhythm, the son. Results show a high correlation between the predictions by the edit distance model and human similarity judgments (r = 0.87); a higher correlation than for the well-known generative theory of tonal music (r = 0.64). In the second experiment, we seek to assess the accuracy of the edit distance model in predicting relatively dissimilar rhythms. The stimuli used are random permutations of the son's inter-onset intervals: 3-3-4-2-4. The results again indicate that the edit distance correlates well with the perceived rhythmic dissimilarity judgments of the subjects (r = 0.76). To gain insight in the relationships between the individual rhythms, the results are also presented by means of graphic phylogenetic trees.},
  langid = {english}
}

@article{ravignaniMeasuringRhythmicComplexity2017,
  title = {Measuring Rhythmic Complexity: A Primer to Quantify and Compare Temporal Structure in Speech, Movement, and Animal Vocalizations},
  shorttitle = {Measuring Rhythmic Complexity},
  author = {Ravignani, Andrea and Norton, Philipp},
  year = {2017},
  journal = {Journal of Language Evolution},
  volume = {2},
  number = {1},
  pages = {4--19},
  doi = {10.1093/jole/lzx002},
  abstract = {Research on the evolution of human speech and phonology benefits from the comparative approach: structural, spectral, and temporal features can be extracted and compared across species in an attempt to reconstruct the evolutionary history of human speech. Here we focus on analytical tools to measure and compare temporal structure in human speech and animal vocalizations. We introduce the reader to a range of statistical methods usable, on the one hand, to quantify rhythmic complexity in single vocalizations, and on the other hand, to compare rhythmic structure between multiple vocalizations. These methods include: time series analysis, distributional measures, variability metrics, Fourier transform, auto- and cross-correlation, phase portraits, and circular statistics. Using computer-generated data, we apply a range of techniques, walking the reader through the necessary software and its functions. We describe which techniques are most appropriate to test particular hypotheses on rhythmic structure, and provide possible interpretations of the tests. These techniques can be equally well applied to find rhythmic structure in gesture, movement, and any other behavior developing over time, when the research focus lies on its temporal structure. This introduction to quantitative techniques for rhythm and timing analysis will hopefully spur additional comparative research, and will produce comparable results across all disciplines working on the evolution of speech, ultimately advancing the field.}
}

@article{roeskeCategoricalRhythmsAre2020,
  title = {Categorical Rhythms Are Shared between Songbirds and Humans},
  author = {Roeske, Tina C. and Tchernichovski, Ofer and Poeppel, David and Jacoby, Nori},
  year = {2020},
  journal = {Current Biology},
  volume = {30},
  number = {18},
  pages = {3544-3555.e6},
  doi = {10.1016/j.cub.2020.06.072},
  abstract = {Rhythm is a prominent feature of music. Of the infinite possible ways of organizing events in time, musical rhythms are almost always distributed categorically. Such categories can facilitate the transmission of culture\textemdash a feature that songbirds and humans share. We compared rhythms of live performances of music to rhythms of wild thrush nightingale and domestic zebra finch songs. In nightingales, but not in zebra finches, we found universal rhythm categories, with patterns that were surprisingly similar to those of music. Isochronous 1:1 rhythms were similarly common. Interestingly, a bias toward small ratios (around 1:2 to 1:3), which is highly abundant in music, was observed also in thrush nightingale songs. Within that range, however, there was no statistically significant bias toward exact integer ratios (1:2 or 1:3) in the birds. High-ratio rhythms were abundant in the nightingale song and are structurally similar to fusion rhythms (ornaments) in music. In both species, preferred rhythms remained invariant over extended ranges of tempos, indicating natural categories. The number of rhythm categories decreased at higher tempos, with a threshold above which rhythm became highly stereotyped. In thrush nightingales, this threshold occurred at a tempo twice faster than in humans, indicating weaker structural constraints and a remarkable motor proficiency. Together, the results suggest that categorical rhythms reflect similar constraints on learning motor skills across species. The saliency of categorical rhythms across humans and thrush nightingales suggests that they promote, or emerge from, the cultural transmission of learned vocalizations. Video Abstract},
  langid = {english}
}
